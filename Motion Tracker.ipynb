{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5e52022-9223-4044-be1f-1925566aa09d",
   "metadata": {},
   "source": [
    "# Motion Tracker\n",
    "\n",
    "Let's see how this goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e070c032-84bf-462c-bfb7-dcdd53f9536e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 640.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from model import MotionDataset, PositionFinder, BoundingBoxFinder, build_model\n",
    "import helper\n",
    "\n",
    "# minmax, minmax_z = helper.get_minmax('train/input.csv', 'test/input.csv')\n",
    "# print(minmax[0], minmax[1])\n",
    "# print(minmax_z[0], minmax_z[1])\n",
    "\n",
    "minmax, minmax_z = helper.get_minmax('train/input.csv', 'test/input.csv')\n",
    "print(minmax[0], minmax[1])\n",
    "# print(minmax_z[0], minmax_z[1])\n",
    "\n",
    "img_width = 256\n",
    "#randomly rotate or transform the images to help training\n",
    "train_transforms = transforms.Compose([\n",
    "#                                         transforms.RandomRotation(30),\n",
    "#                                         transforms.RandomResizedCrop(256),\n",
    "                                        transforms.Resize((img_width,img_width)),\n",
    "                                       transforms.ToTensor()\n",
    "                                       ,transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                             [0.229, 0.224, 0.225])\n",
    "                                      ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                                       transforms.Resize((img_width,img_width)),\n",
    "                                       transforms.ToTensor()\n",
    "                                           ,transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                             [0.229, 0.224, 0.225])\n",
    "                                      ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8899ec-6a9c-4ade-993e-f7b0fc2958cb",
   "metadata": {},
   "source": [
    "## Prepare neural network model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9565a269-deca-45fc-8c7a-13f57d46e172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PositionFinder(\n",
      "  (backbone): Joiner(\n",
      "    (0): Backbone(\n",
      "      (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv1_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_s): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv2_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3_s): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv3_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4_s): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv4_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv4_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv5_s): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv5_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (query_embed): Embedding(22, 512)\n",
      "      (transformer): Transformer(\n",
      "        (encoder): TransformerEncoder(\n",
      "          (layers): ModuleList(\n",
      "            (0): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (3): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (4): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (5): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder): TransformerDecoder(\n",
      "          (layers): ModuleList(\n",
      "            (0): TransformerDecoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (multihead_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "              (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): TransformerDecoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (multihead_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "              (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): TransformerDecoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (multihead_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "              (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (3): TransformerDecoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (multihead_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "              (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (4): TransformerDecoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (multihead_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "              (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (5): TransformerDecoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (multihead_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "              (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): PositionEmbeddingLearned(\n",
      "      (row_embed): Embedding(50, 256)\n",
      "      (col_embed): Embedding(50, 256)\n",
      "    )\n",
      "  )\n",
      "  (transformer): Transformer(\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (3): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (4): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (5): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (query_embed): Embedding(22, 512)\n",
      "  (hidden1): Linear(in_features=32768, out_features=500, bias=True)\n",
      "  (dense1_bn): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (output): Linear(in_features=500, out_features=44, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BoundingBoxFinder(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_s): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (conv2_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_s): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (conv3_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_s): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (conv4_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5_s): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (hidden1): Linear(in_features=131072, out_features=1000, bias=True)\n",
       "  (output): Linear(in_features=1000, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "\n",
    "device = 'cuda'\n",
    "args = {\n",
    "    'img_size' : 256,\n",
    "    'hidden_dim': 512,\n",
    "    'position_embedding': 'learned',\n",
    "    'dropout': 0.2,\n",
    "    'nheads': 8,\n",
    "    'dim_feedforward': 1024,\n",
    "    'enc_layers': 6,\n",
    "    'dec_layers': 6,\n",
    "    'pre_norm': False\n",
    "}\n",
    "args = Args(**args)\n",
    "\n",
    "model = build_model(args)\n",
    "print(model)\n",
    "\n",
    "# Boundaries detection\n",
    "bmodel = BoundingBoxFinder(img_width)\n",
    "bmodel.load_state_dict(torch.load('bmodel.m'))\n",
    "bmodel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5c6159b-3000-47fa-ac73-5daa5610cbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundingBoxFinder(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_s): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (conv2_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_s): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (conv3_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_s): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (conv4_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5_s): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (hidden1): Linear(in_features=131072, out_features=1000, bias=True)\n",
       "  (output): Linear(in_features=1000, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 231,
       "width": 231
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from model import MotionDataset, my_loss\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    inputs = {'images': [], 'details': [], 'bboxes': [], 'prev_positions': []}\n",
    "    targets = {'positions': [], 'confidences': [], 'boundaries': []}\n",
    "    for i in range(len(batch)):\n",
    "\n",
    "        if i != len(batch) - 1:\n",
    "            inputs[\"prev_positions\"].append(batch[i][1][\"positions\"])\n",
    "        else:\n",
    "            for inp in batch[i][0]:\n",
    "                inputs[inp].append(batch[i][0][inp])\n",
    "            for target in batch[i][1]:\n",
    "                targets[target].append(batch[i][1][target])\n",
    "    \n",
    "    inputs[\"images\"] = torch.Tensor(inputs[\"images\"])\n",
    "    inputs[\"details\"] = torch.Tensor(inputs[\"details\"])\n",
    "    inputs[\"bboxes\"] = torch.Tensor(inputs[\"bboxes\"])\n",
    "    inputs[\"prev_positions\"] = torch.Tensor(inputs[\"prev_positions\"])\n",
    "    targets[\"positions\"] = torch.Tensor(targets[\"positions\"])\n",
    "    targets[\"confidences\"] = torch.Tensor(targets[\"confidences\"])\n",
    "    targets[\"boundaries\"] = torch.Tensor(targets[\"boundaries\"])\n",
    "    return inputs, targets\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "#                                         transforms.RandomRotation(30),\n",
    "                                       transforms.Resize((img_width,img_width)),\n",
    "                                       transforms.ToTensor()\n",
    "                                       ,transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                             [0.229, 0.224, 0.225])\n",
    "                                      ])\n",
    "motions = MotionDataset('train/input_new.csv', 'train', train_transforms, minmax, minmax_z, bmodel=bmodel)\n",
    "trainloader = DataLoader(motions, batch_size=4, shuffle=True)\n",
    "inp, output = next(iter(trainloader))\n",
    "# print(inp[\"prev_positions\"][2])\n",
    "helper.imshow(inp[\"images\"][0])\n",
    "\n",
    "motions_test = MotionDataset('test/input_new.csv', 'test', test_transforms, minmax, minmax_z, bmodel=bmodel)\n",
    "testloader = torch.utils.data.DataLoader(motions_test, batch_size=4, shuffle=True)\n",
    "bmodel.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd92d1d1-6bbf-4b47-94bc-c932cde20f06",
   "metadata": {},
   "source": [
    "## Train position finder\n",
    "\n",
    "best loss (L1Loss Sum, 0.003, conv4)\n",
    "0.001 - 0.003\n",
    "\n",
    "\n",
    "```\n",
    " Epoch 22/25) Training loss: 6.749771996027863, Test loss: 10.508017539978027\n",
    "(Epoch 23/25) Training loss: 6.6242278638523295, Test loss: 10.340709686279297\n",
    "(Epoch 24/25) Training loss: 6.520543051754824, Test loss: 10.395054817199707\n",
    "```\n",
    "\n",
    "input contains image (human centered) height, isFacingForward\n",
    "\n",
    "output contains (x,y) coordinates for 22 body parts\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19559b1f-16ca-4d6e-95d2-bd38a7745985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3070\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (NestedTensor, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mNestedTensor\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[32;1mint\u001b[0m)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mNestedTensor\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[32;1mint\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3bc4ceb52302>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m#1. forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"images\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"details\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"bboxes\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;31m#         print(ps[0],  output[\"positions\"][0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m#       print(np.min(ps.cpu().detach().numpy()), np.min(targets.cpu().detach().numpy()))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\pydev\\motion-tracker\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, samples, details, bboxes)\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnested_tensor_from_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecompose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\bihta\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\pydev\\motion-tracker\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, tensor_list)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_list\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNestedTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m         \u001b[0mout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mNestedTensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\bihta\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\pydev\\motion-tracker\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;31m#Convolutional layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1_bn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2_s\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\bihta\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\bihta\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\bihta\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    437\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 439\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    440\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (NestedTensor, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mNestedTensor\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[32;1mint\u001b[0m)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mNestedTensor\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[32;1mint\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "from torch import optim, nn\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.00000007, momentum=0.7, weight_decay=0.0005)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.L1Loss(reduction='sum')\n",
    "bceloss = nn.BCEWithLogitsLoss()\n",
    "print(torch.cuda.get_device_name(0))\n",
    "train_losses, test_losses = [], []\n",
    "epochs = 7\n",
    "# print(model)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "hidden = None\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for inp, output in trainloader:\n",
    "        for k in inp:\n",
    "            inp[k] = inp[k].to(device)\n",
    "        for k in output:\n",
    "            output[k] = output[k].to(device)\n",
    "        \n",
    "        #1. forward pass\n",
    "        ps = model.forward(inp[\"images\"], inp[\"details\"], inp[\"bboxes\"])\n",
    "#         print(ps[0],  output[\"positions\"][0])\n",
    "#       print(np.min(ps.cpu().detach().numpy()), np.min(targets.cpu().detach().numpy()))\n",
    "#       print(np.max(ps.cpu().detach().numpy()), np.max(targets.cpu().detach().numpy()))\n",
    "\n",
    "        #2. calculate loss\n",
    "#         print(ps[0], positions[0])\n",
    "#         _loss = criterion(ps, output[\"positions\"]) / 8\n",
    "#         _bceloss = bceloss(confidences, output[\"confidences\"]) / 5\n",
    "#         loss = _loss + _bceloss\n",
    "        loss = my_loss(ps, output[\"positions\"])\n",
    "        #0. Clear the gradients, do this because gradients are accumulated\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #3. run backward propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # 4. Take an update step and few the new weights\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        # Turn off gradients for validation, saves memory and computations\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for inp, output in testloader:\n",
    "                for k in inp:\n",
    "                    inp[k] = inp[k].to(device)\n",
    "                for k in output:\n",
    "                    output[k] = output[k].to(device)\n",
    "                ps  = model.forward(inp[\"images\"], inp[\"details\"], inp[\"bboxes\"])\n",
    "#                 _loss = criterion(ps, output[\"positions\"]) / 8\n",
    "#                 _bceloss = bceloss(confidences, output[\"confidences\"]) / 5\n",
    "#                 test_loss += _loss + _bceloss\n",
    "                test_loss += my_loss(ps, output[\"positions\"])\n",
    "\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        test_loss = test_loss/len(testloader)\n",
    "        train_loss = running_loss/len(trainloader)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        print(f\"(Epoch {e+1}/{epochs}) Training loss: {train_loss}, Test loss: {test_loss}\")\n",
    "        \n",
    "PATH = 'model.m'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f544c4-fe3e-4c32-af73-3fd12b7f67b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "test_losses = [test_loss.to('cpu') for test_loss in test_losses]\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac03711-c019-4a33-9cd3-b782dc4ee56e",
   "metadata": {},
   "source": [
    "## Use our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8f5312-c4ad-4b8f-ba9c-5726879c3616",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import helper\n",
    "# motions_test = MotionDataset('train/input.csv', 'train', test_transforms, minmax, minmax_z, bmodel=bmodel)\n",
    "motions_test = MotionDataset('test/input_new.csv', 'test', test_transforms, minmax, minmax_z, bmodel=bmodel)\n",
    "testloader = torch.utils.data.DataLoader(motions_test, batch_size=1, shuffle=True)\n",
    "inp, output = next(iter(testloader))\n",
    "\n",
    "model = PositionFinder(img_width)\n",
    "model.load_state_dict(torch.load('model.m'))\n",
    "\n",
    "# img = images[0].view(1, 195075)\n",
    "# img = torch.zeros(1,120000) + 222\n",
    "print(inp[\"images\"].shape)\n",
    "positions, positions_expected = helper.evaluate_model(model, inp, output)\n",
    "# positions = positions[1:]\n",
    "# positions_expected = positions_expected[1:]\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "# zdata = positions.T[1]\n",
    "xdata = positions.T[0]\n",
    "ydata = positions.T[1]\n",
    "ax.set_xlim((0,1))\n",
    "ax.set_ylim((0,1))\n",
    "# ax.set_xlim((0.3,0.7))\n",
    "# ax.set_ylim((0.3,0.7))\n",
    "ax.scatter(xdata, [1 - y for y in ydata]);\n",
    "\n",
    "# zdata_e = positions_expected.T[1]\n",
    "xdata_e = positions_expected.T[0]\n",
    "ydata_e = positions_expected.T[1]\n",
    "ax.scatter(xdata_e, [1 - y for y in ydata_e], marker='^')\n",
    "# helper.imshow(inp[\"images\"][0], xdata=xdata, ydata=ydata)\n",
    "helper.imshow(inp[\"images\"][0], xdata=xdata, ydata=ydata, xdata_e=xdata_e, ydata_e=ydata_e)\n",
    "\n",
    "for i, pos in enumerate(positions):\n",
    "    label = helper.get_label(i)\n",
    "    if label is not None:\n",
    "#         label = label + \"{:.2f}\".format(confidences[0][i].item())\n",
    "#         label = label + \"{:.2f}\".format(output[\"confidences\"][0][i].item())\n",
    "        ax.text(pos[0], 1 - pos[1], label, None, color=\"green\")\n",
    "    \n",
    "for i, pos in enumerate(positions_expected):\n",
    "    label = helper.get_label(i)\n",
    "    if label is not None:\n",
    "        ax.text(pos[0], 1 - pos[1], label, None, color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ac4ee5-6e12-4f35-9657-d41bef0f259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "for i, pos in enumerate(positions):\n",
    "    pos_exp = positions_expected[i]\n",
    "    \n",
    "    dist = np.linalg.norm(pos_exp-pos)\n",
    "    distances.append(dist * 512)\n",
    "\n",
    "print(\"Total distance\", np.array(distances).sum())\n",
    "print(\"Avg distance\", np.array(distances).mean())\n",
    "plt.plot(distances, label='Distances')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d73189-8436-4a42-a919-35dc8c9abbb1",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839fce70-e1e3-48d4-b581-e534509e3ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import MotionDataset\n",
    "motions_test2 = MotionDataset('test2/input.csv', 'test2', test_transforms, minmax, minmax_z, bmodel=bmodel)\n",
    "testloader2 = torch.utils.data.DataLoader(motions_test2, batch_size=1, shuffle=True)\n",
    "inp, output = next(iter(testloader2))\n",
    "\n",
    "positions, positions_expected = helper.evaluate_model(model, inp, output)\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "# zdata = positions.T[1]\n",
    "xdata = positions.T[0]\n",
    "ydata = positions.T[1]\n",
    "ax.set_xlim((0,1))\n",
    "ax.set_ylim((0,1))\n",
    "ax.scatter(xdata, [1 - y for y in ydata]);\n",
    "\n",
    "helper.imshow(inp[\"images\"][0], xdata=xdata, ydata=ydata)\n",
    "\n",
    "for i, pos in enumerate(positions):\n",
    "    label = helper.get_label(i)\n",
    "    if label is not None:\n",
    "#         label = label + \"{:.2f}\".format(confidences[0][i].item())\n",
    "#         label = label + \"{:.2f}\".format(output[\"confidences\"][0][i].item())\n",
    "        ax.text(pos[0], 1 - pos[1], label, None, color=\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5563366e-e345-44f4-81f9-1062a6bc65a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffadcf0-d063-41c4-a7d8-8ba801d9ca3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b83b1d-914d-470d-aea6-2964772bd5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8741744e-824f-454b-8258-094b55539640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
