{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5e52022-9223-4044-be1f-1925566aa09d",
   "metadata": {},
   "source": [
    "# Motion Tracker\n",
    "\n",
    "Let's see how this goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e070c032-84bf-462c-bfb7-dcdd53f9536e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9df53fd7239d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mhelper_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_csv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mhelper_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhelper_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mmaxval_z\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhelper_arr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mminval_z\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhelper_arr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from model import MotionDataset, Network\n",
    "\n",
    "\n",
    "#get min max\n",
    "train_csv = pd.read_csv('train/input.csv')\n",
    "test_csv = pd.read_csv('test/input.csv')\n",
    "maxval = max(train_csv.drop([train_csv.columns[0], train_csv.columns[1]],axis=1).to_numpy().max(), test_csv.drop([test_csv.columns[0], test_csv.columns[1]],axis=1).to_numpy().max())\n",
    "minval = min(train_csv.drop([train_csv.columns[0], train_csv.columns[1]],axis=1).to_numpy().min(), test_csv.drop([test_csv.columns[0], test_csv.columns[1]],axis=1).to_numpy().min())\n",
    "\n",
    "helper_arr = (np.arange(train_csv.shape[1]) + 2) % 3 == 0\n",
    "helper_arr[0], helper_arr[1] = False, False\n",
    "maxval_z = max(train_csv.iloc[:, helper_arr].to_numpy().max(), test_csv.iloc[:, helper_arr].to_numpy().max())\n",
    "minval_z = max(train_csv.iloc[:, helper_arr].to_numpy().min(), test_csv.iloc[:, helper_arr].to_numpy().min())\n",
    "\n",
    "\n",
    "img_width = 256\n",
    "#randomly rotate or transform the images to help training\n",
    "train_transforms = transforms.Compose([\n",
    "                                        transforms.Resize((img_width,img_width)),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor()\n",
    "#                                            ,transforms.Normalize([0.5, 0.5, 0.5], \n",
    "#                                                              [0.5, 0.5, 0.5])\n",
    "                                       ,transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                             [0.229, 0.224, 0.225])\n",
    "                                      ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                                       transforms.Resize((img_width,img_width)),\n",
    "                                       transforms.ToTensor()\n",
    "#                                         ,transforms.Normalize([0.5, 0.5, 0.5], \n",
    "#                                                              [0.5, 0.5, 0.5])\n",
    "                                           ,transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                             [0.229, 0.224, 0.225])\n",
    "                                      ])\n",
    "\n",
    "motions = MotionDataset('train/input.csv', 'train', train_transforms, (minval,maxval), (minval_z, maxval_z))\n",
    "trainloader = DataLoader(motions, batch_size=16, shuffle=True)\n",
    "img, height, transform = next(iter(trainloader))\n",
    "\n",
    "motions_test = MotionDataset('test/input.csv', 'test', test_transforms, (minval,maxval), (minval_z, maxval_z))\n",
    "testloader = torch.utils.data.DataLoader(motions_test, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cc0d93-f770-4a72-aa3a-02b937b1ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper\n",
    "images, height, labels = next(iter(trainloader))\n",
    "helper.imshow(images[0], normalize=False)\n",
    "# images = images.view(images.shape[0], -1)\n",
    "\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8899ec-6a9c-4ade-993e-f7b0fc2958cb",
   "metadata": {},
   "source": [
    "## Prepare neural network model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9565a269-deca-45fc-8c7a-13f57d46e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(img_width)\n",
    "# Set biases to all zeros\n",
    "#model.hidden.bias.data.fill_(0)\n",
    "# sample from random normal with standard dev = 0.01\n",
    "#model.hidden.weight.data.normal_(std=0.01)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b89c61e-f88f-4003-81ac-ddcfa712c21e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be02883b-a2a5-4b4e-af5e-7246d155fdc2",
   "metadata": {},
   "source": [
    "## Train our model\n",
    "\n",
    "best loss \n",
    "Training loss: 0.0042177562236808885\n",
    " Test loss: 0.005721507128328085"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19559b1f-16ca-4d6e-95d2-bd38a7745985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim, nn\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.03333)\n",
    "criterion = nn.MSELoss() \n",
    "# criterion = nn.L1Loss(reduction=\"none\") \n",
    "print(torch.cuda.get_device_name(0))\n",
    "train_losses, test_losses = [], []\n",
    "epochs = 60\n",
    "device = 'cuda'\n",
    "model.to(device)\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, heights, targets in trainloader:\n",
    "        images, heights, targets = images.to(device), heights.to(device), targets.to(device)\n",
    "#         print(images.shape, targets.shape)\n",
    "        #1. forward pass\n",
    "        ps = model.forward(images, heights)\n",
    "#         print(ps.shape, targets.shape)\n",
    "#         print(np.min(ps.cpu().detach().numpy()), np.min(targets.cpu().detach().numpy()))\n",
    "#         print(np.max(ps.cpu().detach().numpy()), np.max(targets.cpu().detach().numpy()))\n",
    "#         print(ps[0], targets[0])\n",
    "        #2. calculate loss\n",
    "        loss = criterion(ps, targets)\n",
    "#         loss = loss.sum(1).sum()\n",
    "#         print(loss)\n",
    "        #0. Clear the gradients, do this because gradients are accumulated\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #3. run backward propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # 4. Take an update step and few the new weights\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "#         print(loss.item())\n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        # Turn off gradients for validation, saves memory and computations\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images, heights, targets in testloader:\n",
    "                images, heights, targets = images.to(device), heights.to(device), targets.to(device)\n",
    "                ps = model.forward(images, heights)\n",
    "                test_loss += criterion(ps, targets)\n",
    "#                 test_loss = test_loss.sum(1).sum().item()\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        test_loss = test_loss/len(testloader)\n",
    "        train_loss = running_loss/len(trainloader)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        print(f\"Training loss: {train_loss}\\n Test loss: {test_loss}\\n\")\n",
    "        \n",
    "PATH = 'model.m'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f544c4-fe3e-4c32-af73-3fd12b7f67b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "test_losses = [test_loss.to('cpu') for test_loss in test_losses]\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac03711-c019-4a33-9cd3-b782dc4ee56e",
   "metadata": {},
   "source": [
    "## Use our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006d9937-e835-44c6-b6bc-d84d2fdf1bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# test_transform = transforms.Compose([transforms.Resize((img_width,img_width)),\n",
    "#                                 transforms.ToTensor()])\n",
    "\n",
    "# test_dataset = datasets.ImageFolder('train/', transform=test_transform)\n",
    "# test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=2, shuffle=True)\n",
    "images, heights, labels = next(iter(testloader))\n",
    "helper.imshow(images[0], normalize=False)\n",
    "helper.imshow(images[1], normalize=False)\n",
    "\n",
    "model.to('cpu')\n",
    "\n",
    "# img = images[0].view(1, 195075)\n",
    "# img = torch.zeros(1,120000) + 222\n",
    "# Turn off gradients to speed up this part\n",
    "print(labels.shape)\n",
    "positions = []\n",
    "positions_expected = []\n",
    "with torch.no_grad():\n",
    "    logps = model.forward(images, height)\n",
    "    logps_denormalized = logps \n",
    "    labels_denormalized = labels \n",
    "    print(np.min(logps_denormalized[0].numpy()), np.min(labels_denormalized[0].numpy()))\n",
    "    print(np.max(logps_denormalized[0].numpy()), np.max(labels_denormalized[0].numpy()))\n",
    "#     print(logps_denormalized[0] * 10 - 5, labels_denormalized[0])\n",
    "    for body_index in range(22):\n",
    "        xyz = []\n",
    "        xyz_e = []\n",
    "        for pos_index in range(3):\n",
    "            xyz.append(logps_denormalized[0][body_index*3+pos_index])\n",
    "            xyz_e.append(labels_denormalized[0][body_index*3+pos_index])\n",
    "        positions.append(xyz)\n",
    "        positions_expected.append(xyz_e)\n",
    "#     print(list(model.parameters()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e251b085-c004-460c-9ca7-efc4604ff684",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = np.array(positions)\n",
    "positions_expected = np.array(positions_expected)\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "zdata = positions.T[1]\n",
    "xdata = positions.T[0]\n",
    "ydata = positions.T[2]\n",
    "ax.scatter3D(xdata, ydata, zdata);\n",
    "\n",
    "zdata_e = positions_expected.T[1]\n",
    "xdata_e = positions_expected.T[0]\n",
    "ydata_e = positions_expected.T[2]\n",
    "ax.scatter3D(xdata_e, ydata_e, zdata_e, marker='^');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ac4ee5-6e12-4f35-9657-d41bef0f259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "for i, pos in enumerate(positions):\n",
    "    pos_exp = positions_expected[i]\n",
    "    dist = np.linalg.norm(pos_exp-pos)\n",
    "    distances.append(dist)\n",
    "\n",
    "plt.plot(distances, label='Distances')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d07eb3-c1d4-411c-a46e-476f6f23c4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5d73189-8436-4a42-a919-35dc8c9abbb1",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
